{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm=OpenAI(model=\"gpt-4o-mini\",api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import Task, AgentChatResponse\n",
    "from typing import Dict,Any\n",
    "from llama_index.core.query_pipeline import  StatefulFnComponent\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    # add your SQL DB url "engine = create_engine()\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine, schema='AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_database = SQLDatabase(\n",
    "engine=engine,\n",
    "schema=\"AI\",\n",
    "metadata\n",
    "=metadata,\n",
    "include_tables=[\"CustomerInvoiceMappingTable\", \"CustomerVehicleMappingTable\", \"MonthlyThroughput\",\"YearlyThroughput\",\"VehicleInvoiceMappingTable\"],\n",
    "sample_rows_in_table_info=3\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "text_to_sql_tmpl = \"\"\"\\\n",
    "Given an input question, first create a syntactically correct {dialect} \\\n",
    "query to run, then look at the results of the query and return the answer. \\\n",
    "You can order the results by a relevant column to return the most \\\n",
    "interesting examples in the database.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema \\\n",
    "description. Be careful to not query for columns that do not exist. \\\n",
    "Pay attention to which column is in which table. Also, qualify column names \\\n",
    "with the table name when needed. \n",
    "\n",
    "You are required to use the following format, \\\n",
    "each taking one line:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use tables listed below.\n",
    "{schema}\n",
    "\n",
    "\n",
    "Question: {query_str}\n",
    "SQLQuery: \\\n",
    "\"\"\"\n",
    "text_to_sql_prompt = PromptTemplate(text_to_sql_tmpl)\n",
    "sql_query_engine = NLSQLTableQueryEngine(text_to_sql_prompt=text_to_sql_prompt,\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"CustomerInvoiceMappingTable\", \"CustomerVehicleMappingTable\", \"MonthlyThroughput\",\"YearlyThroughput\",\"VehicleInvoiceMappingTable\"],\n",
    "    verbose=True,\n",
    ")\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    name=\"sql_tool\",\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_input_fn(state: Dict[str, Any]) -> Dict:\n",
    "    \"\"\"Agent input function.\"\"\"\n",
    "    task=state[\"task\"]\n",
    "    state[\"convo_history\"].append(f\"User: {task.input}\")\n",
    "    convo_history_str=\"\\n\".join(state[\"convo_history\"]) or \"None\"\n",
    "    return {\"input\" : task.input, \"convo_history\": convo_history_str}\n",
    "\n",
    "agent_input_component=StatefulFnComponent(fn=agent_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retry_prompt=PromptTemplate('''\\\n",
    "You are trying to generate a proper natural language query given a user input.\n",
    "\n",
    "This query will then be interpreted by a downstream text-to-SQL agent which\n",
    "will convert the query to a SQL statement. If the agent triggers an error,\n",
    "then that will be reflected in the current conversation history (see below).\n",
    "\n",
    "If the conversation history is None, use the user input. If its not None,\n",
    "generate a new SQL query that avoids the problems of the previous SQL query.\n",
    "########################################\n",
    "Use [AIDatalake].[AI] to query any table\n",
    "For question related to car models:-\n",
    "Use query like this-->\n",
    "WHERE Brand = 'BMW' AND Model LIKE '%X5%'\n",
    "For question related to month of throughput:\n",
    "January 2023 is stored as Jan-23 etc...\n",
    "\n",
    "Input: {input}\n",
    "Convo history (failed attempts): \n",
    "{convo_history}\n",
    "\n",
    "New input:''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Response\n",
    "from typing import Tuple\n",
    "validate_promt=PromptTemplate('''\\\n",
    "Given the user query, validate whether the inferred SQL query and response from executing the query is correct and answers the query.\n",
    "\n",
    "Answer with YES or NO.\n",
    "\n",
    "Query: {input}\n",
    "Inferred SQL query: {sql_query}\n",
    "SQL Response: {sql_response}\n",
    "\n",
    "Result:''')\n",
    "\n",
    "MAX_ITER=10\n",
    "\n",
    "def agent_output_fn(state:Dict[str,Any],output:Response)->Tuple[AgentChatResponse,bool]:\n",
    "    \"Agent output component\"\n",
    "    task=state[\"task\"]\n",
    "    print(f\"> Inferred SQL Query: {output.metadata['sql_query']}\")\n",
    "    print(f\"> SQL Response: {str(output)}\")\n",
    "    state[\"convo_history\"].append(\n",
    "        f\"Assistant (inferred SQL query): {output.metadata['sql_query']}\"\n",
    "    )\n",
    "    state[\"convo_history\"].append(f\"Assistant (response): {str(output)}\")\n",
    "    \n",
    "    #run a mini chain\n",
    "    validate_promt_partial=validate_promt.as_query_component(partial={\n",
    "        \"sql_query\": output.metadata[\"sql_query\"],\n",
    "        \"sql_response\": str(output),\n",
    "              })\n",
    "    qp=QP(chain=[validate_promt_partial,llm])\n",
    "    validate_output=qp.run(input=task.input)\n",
    "    \n",
    "    state[\"count\"]+=1\n",
    "    is_done = False\n",
    "    if state[\"count\"] >= MAX_ITER:\n",
    "        is_done = True\n",
    "    if \"YES\" in validate_output.message.content:\n",
    "        is_done = True\n",
    "\n",
    "    return str(output), is_done\n",
    "\n",
    "\n",
    "agent_output_component = StatefulFnComponent(fn=agent_output_fn)\n",
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    ")\n",
    "\n",
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": agent_input_component,\n",
    "        \"retry_prompt\": retry_prompt,\n",
    "        \"llm\": llm,\n",
    "        \"sql_query_engine\": sql_query_engine,\n",
    "        \"output_component\": agent_output_component,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "qp.add_link(\n",
    "    \"input\", \"retry_prompt\", dest_key=\"input\", input_fn=lambda x: x[\"input\"]\n",
    ")\n",
    "qp.add_link(\n",
    "    \"input\",\n",
    "    \"retry_prompt\",\n",
    "    dest_key=\"convo_history\",\n",
    "    input_fn=lambda x: x[\"convo_history\"],\n",
    ")\n",
    "qp.add_chain([\"retry_prompt\", \"llm\", \"sql_query_engine\", \"output_component\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FnAgentWorker\n",
    "\n",
    "\n",
    "def run_agent_fn(state: Dict[str, Any]) -> Tuple[Dict[str, Any], bool]:\n",
    "    \"\"\"Run agent function.\"\"\"\n",
    "    task, qp = state[\"__task__\"], state[\"query_pipeline\"]\n",
    "    # if first run, then set query pipeline state to initial variables\n",
    "    if state[\"is_first\"]:\n",
    "        qp.set_state({\"task\": task, \"convo_history\": [], \"count\": 0})\n",
    "        state[\"is_first\"] = False\n",
    "\n",
    "    # run the pipeline, get response\n",
    "    response_str, is_done = qp.run()\n",
    "    if is_done:\n",
    "        state[\"__output__\"] = response_str\n",
    "    return state, is_done\n",
    "\n",
    "\n",
    "agent = FnAgentWorker(\n",
    "    fn=run_agent_fn,\n",
    "    initial_state={\"query_pipeline\": qp, \"is_first\": True},\n",
    ").as_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retry_prompt with input: \n",
      "input: What is the retail throughput for Bundoora BMW for january 2023\n",
      "convo_history: User: What is the retail throughput for Bundoora BMW for january 2023\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: You are trying to generate a proper natural language query given a user input.\n",
      "\n",
      "This query will then be interpreted by a downstream text-to-SQL agent which\n",
      "will convert the query to a SQL statement. I...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module sql_query_engine with input: \n",
      "input: assistant: What is the retail throughput for the Bundoora location of BMW for Jan-23?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module output_component with input: \n",
      "output: I'm sorry, but there seems to be an error in retrieving the retail throughput data for the Bundoora location of BMW for Jan-23. It appears that the SQL query provided is invalid. Please double-check t...\n",
      "\n",
      "\u001b[0m> Inferred SQL Query: SELECT Dealer_Name, Throughput_Retail\n",
      "FROM MonthlyThroughput\n",
      "WHERE Month = 'Jan-23' AND Dealer_Name = 'Bundoora' AND Brand = 'BMW'\n",
      "> SQL Response: I'm sorry, but there seems to be an error in retrieving the retail throughput data for the Bundoora location of BMW for Jan-23. It appears that the SQL query provided is invalid. Please double-check the query syntax and try again.\n",
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retry_prompt with input: \n",
      "input: What is the retail throughput for Bundoora BMW for january 2023\n",
      "convo_history: User: What is the retail throughput for Bundoora BMW for january 2023\n",
      "Assistant (inferred SQL query): SELECT Dealer_Name, Throughput_Retail\n",
      "FROM MonthlyThroughput\n",
      "WHERE Month = 'Jan-23' AND Dealer_Nam...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n",
      "messages: You are trying to generate a proper natural language query given a user input.\n",
      "\n",
      "This query will then be interpreted by a downstream text-to-SQL agent which\n",
      "will convert the query to a SQL statement. I...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_query_engine with input: \n",
      "input: assistant: What is the retail throughput for Bundoora BMW for Jan-23?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module output_component with input: \n",
      "output: The retail throughput for Bundoora BMW in January 2023 was 385 units.\n",
      "\n",
      "\u001b[0m> Inferred SQL Query: SELECT Dealer_Name, Throughput_Retail\n",
      "FROM MonthlyThroughput\n",
      "WHERE Month = 'Jan-23' AND Dealer_Name = 'Bundoora BMW'\n",
      "> SQL Response: The retail throughput for Bundoora BMW in January 2023 was 385 units.\n",
      "The retail throughput for Bundoora BMW in January 2023 was 385 units.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"What is the retail throughput for Bundoora BMW for january 2023\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing-tanmay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
